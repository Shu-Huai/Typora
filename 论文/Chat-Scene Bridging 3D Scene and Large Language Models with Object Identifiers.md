# Chat-Scene: Bridging 3D Scene and Large Language Models with Object Identifiers

## 基本信息

聊天场景：使用对象标识符桥接 3D 场景和大型语言模型

一种能够定位和引用物体的大语言模型

NeurIPS 2024

arxiv：[[2312.08168\] Chat-Scene: Bridging 3D Scene and Large Language Models with Object Identifiers](https://arxiv.org/abs/2312.08168)

Github：[ZzZZCHS/Chat-Scene: Code for "Chat-Scene: Bridging 3D Scene and Large Language Models with Object Identifiers" (NeurIPS 2024)](https://github.com/ZzZZCHS/Chat-Scene)

## 摘要

3D 大型语言模型（LLM）的最新进展已经证明了 3D 场景理解的有希望的能力。然而，以前的方法在复杂场景理解的一般引用和接地能力方面表现出不足。在本文中，我们介绍了使用对象标识符和以对象为中心的表示与对象级别的场景进行交互。具体来说，我们将输入的 3D 场景分解为一组对象提议，每个提议都分配了一个唯一的标识符令牌，这使得在用户助理交互期间能够高效地进行对象引用和接地。鉴于场景语言数据的稀缺性，我们将场景嵌入建模为一系列显式对象级嵌入，源自语义丰富的 2D 或 3D 表示。通过使用对象标识符，我们将多样化的 3D 场景语言任务转换为统一的问答格式，促进联合训练，而无需额外的特定任务头。通过对所有下游任务的最小微调，我们的模型在基准测试（包括 ScanRefer、Multi3DRefer、Scan2Cap、ScanQA 和 SQA3D）上显着优于现有方法。

## 研究背景

随着大语言模型（LLMs）的发展，多模态大语言模型（MLLMs）兴起，在 2D 领域已取得显著进展，但 3D MLLMs 仍面临诸多挑战。在 3D 场景理解中，对象引用和定位至关重要，然而当前 3D MLLMs 在这方面能力不足。现有 3D MLLMs 在处理 3D 场景时，多将其转换为隐藏的场景嵌入，缺乏对单个对象实例的有效解释能力。并且，3D 场景语言数据集规模相对较小，数据稀缺，影响模型训练效果。基于这些问题，本文旨在探索更有效的方法来实现 3D MLLMs 中的对象引用和定位，并减轻数据稀缺的影响。

## 主要方法

### 物体标识符赋能3D场景交互

为每个物体分配独特的标识符，从而在复杂场景中实现物体的精准指代和定位

在之前的大语言模型中，往往依赖冗长的文字描述来指代或定位物体

通过这一设计，能够有效减少现有模型因描述模糊而引发的理解障碍。

![img](http://public.file.lvshuhuai.cn/图床\640-1731408634135-7.png)

### 物体级的多模态嵌入表示

通过大规模预训练的物体级嵌入表示，来尽量减少对大量场景语言数据的依赖。我们的模型通过多模态物体级嵌入，结合了 3D 和 2D 视觉模型的语义信息，以提升对场景的理解深度和广度。

具体而言，Chat-Scene 模型首先利用预训练的 3D 检测器将场景分解为若干物体，并为每个物体生成一个独特的标识符。然后，模型通过 3D 和 2D 编码器分别从 3D 点云和多视角图像中提取物体特征。

我们通过线性投影层将这些特征映射到语言模型的嵌入空间，从而形成一系列物体级嵌入以表示整个 3D 场景。我们希望这种设计在减少数据需求的同时，能够显著提升模型在多种 3D 任务中的性能。

![img](http://public.file.lvshuhuai.cn/图床\640-1731408706671-10.png)

### 统一问答框架和单阶段联合训练

将所有 3D 场景理解任务转化为统一的问答框架。不论是 3D 场景问答、视觉定位，还是密集描述任务，我们的模型都可以通过这一问答框架进行训练与推理。

![img](http://public.file.lvshuhuai.cn/图床\640-1731408752690-13.png)

选择了联合训练策略，在训练中同步优化投影层和语言模型的参数，避免了额外的对齐阶段。这种策略不仅简化了训练流程，还显著降低了训练开销，同时在不同任务中展示了优异的场景理解表现。

## 实验

在 ScanRefer、Multi3DRefer、Scan2Cap、ScanQA 和 SQA3D 等数据集上测试了模型的性能，实验结果显示模型在这些任务中的表现得到了显著提升