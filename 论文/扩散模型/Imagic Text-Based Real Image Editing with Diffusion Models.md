# Imagic: Text-Based Real Image Editing with Diffusion Models

## 基本信息

使用扩散模型进行基于文本的真实图像编辑

一种基于文本语义的真实图像编辑方法

CVPR 2023

论文：[Imagic Text-Based Real Image Editing with Diffusion Models.pdf](http://public.file.lvshuhuai.cn/Imagic Text-Based Real Image Editing with Diffusion Models.pdf)

arxiv：[Imagic: Text-Based Real Image Editing with Diffusion Models (arxiv.org)](https://arxiv.org/abs/2210.09276)

项目主页：[https://imagic-editing.github.io/](https://imagic-editing.github.io/)

未开源

## 摘要

文本条件图像编辑最近引起了相当大的关注。然而，目前大多数方法要么局限于特定的编辑类型（例如，对象叠加、风格迁移），要么适用于合成生成的图像，要么需要同一对象的多个输入图像。在本文中，我们首次展示了对单个真实图像应用复杂（例如，非刚性）文本引导语义编辑的能力。例如，我们可以在保留图像原始特征的同时，改变图像中一个或多个对象的姿势和组成。我们的方法可以让站立的狗坐下或跳跃，让鸟展开翅膀等等 —— 这些都在用户提供的单个高分辨率自然图像中实现。与以前的工作相反，我们提出的方法只需要一个输入图像和一个目标文本（所需的编辑）。它在真实图像上运行，并且不需要任何额外的输入（例如图像掩码或对象的其他视图）。我们将我们的方法称为 “Imagic”，它利用预先训练的文本到图像扩散模型来完成这项任务。它生成一个与输入图像和目标文本都对齐的文本嵌入，同时微调扩散模型以捕捉图像特定的外观。我们在来自不同领域的众多输入上展示了我们方法的质量和多功能性，展示了大量高质量的复杂语义图像编辑，所有这些都在一个统一的框架内。

## 研究背景

对输入的图像在给定的文本语义条件下进行编辑称为文本条件图像编辑（Text-conditioned image editing）。由于深度学习技术的发展和各种图像生成模型的提出，这项任务最近引起了人们的广泛研究。近年来，在这项任务上开展的许多研究已经展现出一些效果，但仍在不同程度上存在一些缺点。

一些方法局限于一组特定的编辑，例如在输入的图像上添加或删除一些语义对象；另一些方法局限于特定领域的图像处理，如医学、自动化工业控制等；还有些方法依赖于多角度图像、蒙版图像等更多输入。

扩散模型能够很好地理解输入文本的语义，从输入图片或文字中生成或合成高质量的图片基于此，论文尝试提出一种基于扩散模型文本语义图像编辑方法来缓解上述问题。

## 研究方法

论文提出的文本语义图像编辑方法大致上需要经历三个步骤，分别为文本嵌入优化、模型微调和文本嵌入插值，如图所示。

![img](http://public.file.lvshuhuai.cn/images/PixPin_2024-10-01_14-40-02.png)

### 文本嵌入优化

在这一步中，论文首先对于给定输入文本的文本嵌入进行了优化，获得与给定图像最匹配的文本嵌入，论文使用了预训练的扩散模型中的文本嵌入层来执行语义操作。

给定输入文本首先被传入扩散模型的文本编码器，输出其经过编码后的文本嵌入，记为$\mathbf e_{tgt}\in \mathbb{R}^{T\times d}$，其中$T$是给定目标文本中的标记数，$d$是标记嵌入维度。随后，对于预训练的扩散模型$f_\theta$，冻住其参数$\theta$，使用去噪扩散优化得到的$\mathbf e_{tgt}$。损失函数：$\mathcal L_{\mathbf x,\mathbf e,\theta}=\mathbb E_{t,\epsilon}[\Vert \epsilon-f_{\theta}(\mathbf x_t,t,\mathbf e)\Vert]_2^2$。

其中，$\mathbf x_t$是使用$\epsilon\sim\mathcal{N}(0,\mathbf{I})$获得的输入图像$\mathbf{x}$的加噪图像。使用该损失函数对文本嵌入进行相对较少迭代次数的优化，就可以使获得的最优文本嵌入$\mathbf{e}_{opt}$既能够在文本空间中接近初始目标文本嵌入，又可以与输入图像尽可能接近。

### 模型微调

在上一步中，优化得到的文本嵌入$\mathbf{e}_{opt}$可能会导致在扩散过程中与原始图像在细节或其他方面不一致。因此，需要优化扩散模型来缩小差距。

具体而言，方法冻结了优化后的文本嵌入，使用公式给出的损失函数对扩散模型的参数集$\theta$进行优化。这种优化不仅适用于扩散模型的生成器，也适用于扩散模型中其他存在的辅助函数，如超分辨率模型。文中提到，根据经验，在推理时，将$\mathbf e_{tgt}$输入辅助模型比使用$\mathbf e_{opt}$表现更好。因此，在超分辨率模型上的优化选择使用$\mathbf{e}_{tgt}$进行。

### 文本嵌入插值

方法的第三步是将$\mathbf e_{tgt}$和$\mathbf e_{opt}$进行简单线性插值：$  \overline{\mathbf{e}}=\eta\cdot\mathbf e_{tgt}+(1-\eta)\cdot\mathbf{e}_{opt}$。

将第二步中得到的微调模型应用于$\overline{\mathbf{e}}$，能够使输入图像沿着目标文本嵌入的方向改变，从而获得经过编辑后的图像。

## 实验

论文提出的Imagic可以运行于不同的预训练扩散模型上。论文在Imagen和Stable Diffusion这两种模型上进行了实验。

在定性实验中，论文将所提出的方法应用于来自不同领域的大量真实图像，并对其样式、外观、颜色、姿势和构图等方面进行简单的编辑。在两个模型上，分别对文本嵌入进行了100次迭代优化，并基于优化后的图像对模型进行1500次迭代的优化。实验表明，$\eta$对编辑结果有显著影响，论文选择的$\eta$位于0.6和0.8之间。实验结果如图所示。

![img](http://public.file.lvshuhuai.cn/images/PixPin_2024-10-01_16-10-31.png)

在定量实验中，论文引入了TEdBench。作者对实验数据进行了人类感知评估研究。结果表明，相对于SDEdit、DDIB和Text2LIVE等方法，评估者认为论文提出的方法在编辑后的图像质量上更优。

## 局限性

在某些情况下，本文提出的方法不能很好地理解文本给出的编辑。在其他情况下，对对象的编辑但它会影响外部图像细节，例如缩放或相机角度。